
based on this and project files, and the previous discussion:
* write a prompt for an all-intelligent ai to pick up the excellent work you have already done
* be explicit about the design goals, the data flow, the relevant bits of recent logs. Ensure that existing assets are reused (storage service for example). Make sure that the resulting solution is elegant, simple and solves the issue. Also be explicit about gotchas and technologies used and where to find relevant information in the project.


Be militant about reusing working parts and only changing necessary bit, with full explanation as to why you did.

When providing Elixir code that uses Ecto queries, please ensure that:

All necessary modules are imported, especially 'import Ecto.Query' when using query functions.
Ecto queries are written using proper syntax, preferably as separate functions for complex queries.
The pin operator (^) is used only in appropriate contexts, such as pattern matching or within properly constructed Ecto queries.
All variables used in queries are correctly scoped and defined.
The code adheres to both Elixir and Ecto best practices and syntax rules.

make the prompt such that if I send it to an AI, it'll be as if I was continuing this chat with you. Give any heads up to the ai you wish.

Current goal I would like to acheive:
I have analysed all the bulk insert logic, schemas, migrations, and decided that using system generated sequential ids as foreign keys is the problem. I would like to start using a fast to generate UID instead that I can know in advance and therefore not run into missing IDs and other problems, and always have these IDs to hand when inserting thousands of rows at once.

latest error:
```
16:25:38.858 [debug] QUERY OK source="chunks" db=0.8ms
INSERT INTO "chunks" ("size","uid","hash","inserted_at","updated_at") VALUES ($1,$2,$3,$4,$5),($6,$7,$8,$9,$10),($11,$12,$13,$14,$15),($16,$17,$18,$19,$20),($21,$22,$23,$24,$25),($26,$27,$28,$29,$30),($31,$32,$33,$34,$35),($36,$37,$38,$39,$40) ON CONFLICT DO NOTHING [6148, "01912882-af28-7098-a06a-1581f844a1ba", "609ef3946267dacb34d57aa28b378ab3", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 6148, "01912882-af28-7156-b1fc-8fffa9382de3", "ba7b86fe76a3af7529afb8acd2fdd33d", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 39, "01912882-af28-784b-a598-a6f1bb6a2ea4", "e26a4800dd83b35bda59c593a80cee05", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 97, "01912882-af28-7038-ae25-3f7e5d19fdf6", "e1c32f90f02efb36ac2a34ba7609c04f", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 642, "01912882-af28-7e44-af2f-16d0a2acf10a", "84deda2791f54300e3b79abb178f8a80", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 124917, "01912882-af28-720e-ad4d-e1d28aa6e30b", "66ba62d84d2560a815ac70103fdc7b3f", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 778, "01912882-af28-7b43-960f-ed3a16fe3d33", "ac6e840501953af02672375941dffe3b", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 778, "01912882-af28-76fc-9a1d-8ff4b3463771", "ac6e840501953af02672375941dffe3b", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38]]
16:25:38.858 [debug] Preparing to insert 8 file chunks
16:25:38.860 [debug] QUERY OK source="chunks" db=0.6ms
SELECT c0."hash", c0."uid" FROM "chunks" AS c0 WHERE (c0."hash" = ANY($1)) [["609ef3946267dacb34d57aa28b378ab3", "ba7b86fe76a3af7529afb8acd2fdd33d", "e26a4800dd83b35bda59c593a80cee05", "e1c32f90f02efb36ac2a34ba7609c04f", "84deda2791f54300e3b79abb178f8a80", "66ba62d84d2560a815ac70103fdc7b3f", "ac6e840501953af02672375941dffe3b", "ac6e840501953af02672375941dffe3b"]]
16:25:38.861 [debug] QUERY OK source="file_results" db=0.5ms
SELECT f0."path", f0."uid" FROM "file_results" AS f0 WHERE (f0."path" = ANY($1) AND (f0."hash_result_uid" = $2)) [["examplehash/.DS_Store", "examplehash/hiveforge_controller/.DS_Store", "examplehash/hiveforge_controller/.dockerignore", "examplehash/hiveforge_controller/.formatter.exs", "examplehash/hiveforge_controller/.gitignore", "examplehash/hiveforge_controller/folder_with_file/hiveforge-controller.log", "examplehash/hiveforge_controller/values-example copy.yaml", "examplehash/hiveforge_controller/values-example.yaml"], "01912882-af15-7805-b0b3-af4c35733279"]
16:25:38.863 [debug] QUERY ERROR source="file_chunks" db=0.9ms
INSERT INTO "file_chunks" ("offset","uid","inserted_at","updated_at","sequence","hash_result_uid","chunk_uid","file_result_uid") VALUES ($1,$2,$3,$4,$5,$6,$7,$8),($9,$10,$11,$12,$13,$14,$15,$16),($17,$18,$19,$20,$21,$22,$23,$24),($25,$26,$27,$28,$29,$30,$31,$32),($33,$34,$35,$36,$37,$38,$39,$40),($41,$42,$43,$44,$45,$46,$47,$48),($49,$50,$51,$52,$53,$54,$55,$56),($57,$58,$59,$60,$61,$62,$63,$64) ON CONFLICT DO NOTHING [0, "01912882-af2a-749e-a2d5-1f780a276d3a", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-7098-a06a-1581f844a1ba", "01912882-af25-758c-9f5a-6d8fe567ec0d", 0, "01912882-af2a-7b6a-9066-2e321f470b88", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-7156-b1fc-8fffa9382de3", "01912882-af25-726b-828f-bbb7041e9250", 0, "01912882-af2a-7e11-94c8-3261f09d5009", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-784b-a598-a6f1bb6a2ea4", "01912882-af25-78da-b7f0-b0db60aa39a8", 0, "01912882-af2a-7505-b6de-c9a5cdd120e0", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-7038-ae25-3f7e5d19fdf6", "01912882-af25-7536-8e1e-b7dd5728db5f", 0, "01912882-af2a-732e-8e93-abdea8d486f6", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-7e44-af2f-16d0a2acf10a", "01912882-af25-7c3e-a2b5-7faf3340eced", 0, "01912882-af2a-740b-8d43-87de447c43cb", ~N[2024-08-06 16:25:38], ~N[2024-08-06 16:25:38], 0, "01912882-af15-7805-b0b3-af4c35733279", "01912882-af28-720e-ad4d-e1d28aa6e30b", "01912882-af25-71c8-88b4-3911ca91afdf", 0, "01912882-af2a-7e0b-b401-7e6c9b53396f", ...]
16:25:38.864 [debug] QUERY OK db=0.5ms
rollback []
16:25:38.864 [error] Error in ProtectedRouter: ** (Plug.Conn.WrapperError) ** (Postgrex.Error) ERROR 23502 (not_null_violation) null value in column "file_path" of relation "file_chunks" violates not-null constraint

    table: file_chunks
    column: file_path

Failing row contains (01912882-af2a-749e-a2d5-1f780a276d3a, 0, 0, null, 01912882-af25-758c-9f5a-6d8fe567ec0d, 01912882-af28-7098-a06a-1581f844a1ba, 01912882-af15-7805-b0b3-af4c35733279, 2024-08-06 16:25:38, 2024-08-06 16:25:38).
    (ecto_sql 3.11.3) lib/ecto/adapters/sql.ex:1054: Ecto.Adapters.SQL.raise_sql_call_error/1
    (ecto_sql 3.11.3) lib/ecto/adapters/sql.ex:925: Ecto.Adapters.SQL.insert_all/9
    (ecto 3.11.2) lib/ecto/repo/schema.ex:59: Ecto.Repo.Schema.do_insert_all/7
    (hiveforge_controller 0.1.0) lib/hiveforge_controller/services/hash_processing_service.ex:231: HiveforgeController.Services.HashProcessingService.process_file_chunks/2
    (hiveforge_controller 0.1.0) lib/hiveforge_controller/services/hash_processing_service.ex:23: anonymous fn/1 in HiveforgeController.Services.HashProcessingService.process_hash_result/1
    (ecto_sql 3.11.3) lib/ecto/adapters/sql.ex:1358: anonymous fn/3 in Ecto.Adapters.SQL.checkout_or_transaction/4
    (db_connection 2.7.0) lib/db_connection.ex:1756: DBConnection.run_transaction/4
    (hiveforge_controller 0.1.0) lib/hiveforge_controller/controllers/hash_controller.ex:86: HiveforgeController.Controllers.HashController.start_processing_job/1

16:25:38.864 [info] Sent 500 in 41ms
```






You are continuing the development of the HiveforgeController project, focusing on implementing a UID-based system for bulk inserts. The current goal is to replace system-generated sequential IDs with pre-generated UIDs across all relevant schemas to solve issues with bulk inserts and foreign key constraints.

Context and Design Goals:
1. Replace system-generated sequential IDs with pre-generated UIDs across all relevant schemas.
2. Ensure UIDs can be generated in advance and are available during bulk inserts.
3. Maintain data integrity and foreign key relationships.
4. Optimize bulk insert performance.
5. Keep the solution elegant and simple while solving the core issue.

Current Architecture Overview:
- The project uses Elixir and the Plug framework (not Phoenix).
- Data persistence is handled by Ecto with a PostgreSQL database.
- The main components involved are:
  - Schemas: HashResult, DirectoryEntry, FileResult, Chunk, FileChunk
  - Services: HashProcessingService, StorageService
  - Controllers: HashController

Recent Logs:
The most recent error encountered was a null value violation for the 'file_path' column in the 'file_chunks' table during a bulk insert operation.

Implementation Steps:
1. Choose a UID generation method (e.g., UUIDv7 or ULID).
2. Update schemas to use string-based UID fields instead of integer IDs.
3. Modify migrations to reflect schema changes.
4. Update the HashProcessingService to generate and use UIDs during bulk inserts.
5. Adjust queries and relationships in the codebase to work with the new UID system.

Gotchas and Considerations:
- Ensure all foreign key relationships are updated to use UIDs.
- Be cautious of existing data - you may need to write a data migration script.
- Update any code that assumes integer IDs (e.g., ID incrementing logic).
- Consider the performance impact of string-based UIDs vs. integer IDs.
- Ensure the UID generation method is sufficiently random and unique.

Technologies and Libraries:
- Elixir and Plug framework
- Ecto for database interactions
- PostgreSQL as the database
- Consider using the `uniq` library for UID generation (add to `mix.exs` if not present)

Relevant Project Files:
- Schemas: `lib/hiveforge_controller/schemas/`
- Services: `lib/hiveforge_controller/services/`
- Migrations: `priv/repo/migrations/`
- Controllers: `lib/hiveforge_controller/controllers/`

Important Notes:
- Reuse existing assets like the StorageService where possible.
- Only modify necessary parts of the codebase, providing full explanations for any changes.
- When writing Ecto queries, ensure proper imports (especially `import Ecto.Query`), correct syntax, appropriate use of the pin operator (^), and adherence to Elixir and Ecto best practices.

Your task is to continue the implementation of the UID-based system, focusing on resolving the null value violation in the bulk insert process. Provide detailed code changes, explanations, and any necessary migrations or schema updates.
